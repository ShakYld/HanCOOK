{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "restaurants_df = pd.read_csv('/content/korean_restaurants_id.csv')\n",
        "\n",
        "# Handling missing values (example: fill with a placeholder or remove rows)\n",
        "restaurants_df.fillna('Unknown', inplace=True)\n",
        "\n",
        "# Extract the first two words from road address\n",
        "def extract_first_two_words(address):\n",
        "    words = address.split()\n",
        "    if len(words) >= 2:\n",
        "        return ' '.join(words[:2])\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# Extract the first words from jibun address\n",
        "def extract_first_words(address):\n",
        "    words = address.split()\n",
        "    if len(words) >= 1:\n",
        "        return ' '.join(words[:1])\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "restaurants_df['roadaddr_part'] = restaurants_df['roadaddr'].apply(extract_first_two_words)\n",
        "\n",
        "restaurants_df['jibunaddr_part'] = restaurants_df['jibunaddr'].apply(extract_first_words)\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "encoded_columns = one_hot_encoder.fit_transform(restaurants_df[['category', 'roadaddr_part', 'jibunaddr_part']])\n",
        "encoded_df = pd.DataFrame(encoded_columns, columns=one_hot_encoder.get_feature_names_out(['category', 'roadaddr_part', 'jibunaddr_part']))\n",
        "\n",
        "# Normalize numerical columns #except review\n",
        "scaler = StandardScaler()\n",
        "normalized_columns = scaler.fit_transform(restaurants_df[['meancost']])\n",
        "normalized_df = pd.DataFrame(normalized_columns, columns=['meancost'])\n",
        "\n",
        "# Combine the processed columns\n",
        "restaurants_processed_df = pd.concat([restaurants_df[['restaurant_id', 'name', 'dishes', 'review']], encoded_df, normalized_df], axis=1)\n",
        "\n",
        "restaurants_processed_df.to_csv('/content/korean_restaurants_processed.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YAalCq0n6Mn",
        "outputId": "ec1ca5cd-8b14-4478-9693-28d2a15e55c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "users_df = pd.read_csv('/content/users_dataset_15000.csv')\n",
        "\n",
        "# Handling missing values\n",
        "users_df.fillna('Unknown', inplace=True)\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "encoded_columns = one_hot_encoder.fit_transform(users_df[['gender', 'location']])\n",
        "encoded_df = pd.DataFrame(encoded_columns, columns=one_hot_encoder.get_feature_names_out(['gender', 'location']))\n",
        "\n",
        "# Combine the processed columns\n",
        "users_processed_df = pd.concat([users_df[['user_id', 'age']], encoded_df], axis=1)\n",
        "\n",
        "users_processed_df.to_csv('/content/users_dataset_processed.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E29EFSicn_B2",
        "outputId": "7f432c92-5898-4bca-e462-554a65dff3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "interactions_df = pd.read_csv('/content/interactions_dataset_15000.csv')\n",
        "\n",
        "# Handling missing values\n",
        "interactions_df.dropna(subset=['rating'], inplace=True)\n",
        "\n",
        "# Convert timestamp to datetime\n",
        "interactions_df['timestamp'] = pd.to_datetime(interactions_df['timestamp'])\n",
        "\n",
        "interactions_df.to_csv('/content/interactions_dataset_processed.csv', index=False)"
      ],
      "metadata": {
        "id": "HbhtSiKfoBc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Merge datasets for modeling\n",
        "merged_df = pd.merge(interactions_df, users_processed_df, on='user_id')\n",
        "merged_df = pd.merge(merged_df, restaurants_processed_df, on='restaurant_id')\n",
        "\n",
        "# Save the final processed dataset\n",
        "merged_df.to_csv('/content/processed_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "yhNXGbp3oFa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zomato dataset"
      ],
      "metadata": {
        "id": "UVOlwD2S9cMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zomato_df = pd.read_csv('/content/zomato_with_korean.csv')\n",
        "\n",
        "# 처음부터 663번째까지의 데이터 유지\n",
        "df = zomato_df[:662]\n",
        "\n",
        "# 수정된 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv('/content/zomato_modified.csv', index=False)"
      ],
      "metadata": {
        "id": "xg2ZH63p4fkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zomato_df = pd.read_csv('/content/zomato_modified.csv')"
      ],
      "metadata": {
        "id": "r1miFJHt5aJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zomato_df.columns.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXcTBwHy5cUn",
        "outputId": "ba733624-1353-4c70-e81d-46d6251a95d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name',\n",
              " 'rate',\n",
              " 'dish_liked',\n",
              " 'cuisines',\n",
              " 'cost',\n",
              " 'reviews_list',\n",
              " 'city',\n",
              " 'Mean Rating']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "zomato_df.fillna('Unknown', inplace=True)\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "encoded_columns = one_hot_encoder.fit_transform(zomato_df[['cuisines', 'city']])\n",
        "encoded_df = pd.DataFrame(encoded_columns, columns=one_hot_encoder.get_feature_names_out(['cuisines', 'city']))\n",
        "\n",
        "# Normalize numerical columns #except review\n",
        "scaler = StandardScaler()\n",
        "normalized_columns = scaler.fit_transform(zomato_df[['cost', 'Mean Rating']])\n",
        "normalized_df = pd.DataFrame(normalized_columns, columns=['cost', 'Mean Rating'])\n",
        "\n",
        "# Combine the processed columns\n",
        "zomato_processed_df = pd.concat([zomato_df[['name', 'rate', 'dish_liked', 'reviews_list']], encoded_df, normalized_df], axis=1)\n",
        "\n",
        "zomato_processed_df.to_csv('/content/zomato_processed.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O1A6ik515-n",
        "outputId": "46597e35-f837-4552-bf42-81ae6923784a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}
